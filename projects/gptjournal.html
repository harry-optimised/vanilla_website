<!doctype html>

<html lang="en">
    <head>
        <meta charset="utf-8">
        <title>Building NLP Powered Applications Using the OpenAI API</title>
        <meta name="description" content="As an indy developer interested in using natural language processing capabilities in my own projects, I wanted to see how easy it would be to use the OpenAI API and some local unstructured textual data to build something useful.">
        <meta name="author" content="Harry Turner">
        <meta name="keywords"
              content="openai, gpt, gpt-3, application, natural language processing">
        <link rel="icon" type="image/ico" href="../images/favicon.ico">
        <link href="../styles/styles.css" type="text/css" rel="stylesheet" />
        <link href="https://fonts.googleapis.com/css2?family=Manrope:wght@200;300;400;500;600;700;800&display=swap" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css2?family=Lora:ital,wght@0,400;0,500;1,400&display=swap" rel="stylesheet">
        <link rel=“canonical” href=“https://www.harrysprojects.com/projects/artificial.html” />
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <script src="../js/Navbar.js" type="text/javascript" defer></script>
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-180754451-1"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'UA-180754451-1');
        </script>
    </head>
    <body>
        <div class="page-container">

            <nav-bar></nav-bar>

            <div>
                <h1>Building NLP Powered Applications Using the OpenAI API</h1>
                <p><i>29th December 2022</i></p>

                <p>
                    As large language models improve, I believe we're going to see a wave of
                    new, clever applications built on top of them. As an indy developer
                    interested in using natural language processing capabilities in my own
                    projects, I wanted to see how easy it would be to use the OpenAI API and
                    some local unstructured textual data to build something useful.
                </p>
                <p>
                    The text data I had available was the complete set of notes from my journal
                    which I've been writing on and off for the past seven years. Journaling is
                    a method I use to think things through, writing can be clarifying. Within this
                    dataset were descriptions of things I had done, projects I had worked on, and
                    opinions of various events.
                </p>
                <p>
                    I wanted to see whether I could use natural language processing, such as
                    the GPT3 language model from OpenAI, to gain interesting insight into my
                    own mind based on the things I had written. I wanted to be able to;
                    summarise things I had done on particular days, summarise opinions about
                    things I may have written about, and generate new ideas for things I might
                    want to try based upon an understanding of who I was as a person (that I
                    hoped GPT3 would be able to figure out).
                </p>
                <p>
                    I chose to build this application on top of the OpenAI API because it
                    offers a simple interface for working with several powerful language models,
                    including generation of document embeddings, and text completion. I studied
                    the documentation at <a href="https://beta.openai.com/overview">OpenAI</a>,
                    focussing on Text Completion and Embeddings. I also used the examples
                    within the <a href="https://github.com/openai/openai-cookbook">OpenAI
                    Cookbook</a>, specifically <a
                        href="https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb">this example</a>.
                </p>
                <p>
                    What follows, is a slightly more in depth walk-through of how I built this
                    application, using the capabilities provided by OpenAI to perform useful
                    tasks that were relevant to me. I'll discuss how I prepared and cleaned the
                    data, and how I generated the prompts to the text completion model. The
                    notebook for this exercise can be found <a href="">here</a>.
                </p>

                <h3>Roadmap</h3>
                <p>
                    It's trivial to ask questions of GPT3 and receive answers. Try this for
                    free at the <a href="https://beta.openai.com/playground">OpenAI
                    Playground</a>. The problem though, is that the GPT3 training data doesn't
                    include my journal, so it doesn't know anything about me.
                </p>
                <p>
                    There are two approaches for getting GPT3 to answer questions about things
                    it doesn't know, the first is to fine-tune a model on a custom dataset. The
                    second is prompt engineering.
                </p>
                <p>
                    I haven't yet tried fine-tuning. I don't have much data, and training/using
                    fine-tuned models is more expensive. For these reasons I chose to use
                    prompt engineering, however I may come back to try this another time.
                </p>
                <p>
                    In OpenAI's own words, prompt engineering is  how you <i>"program the
                    model"</i>. There are lots of resources springing up around this
                    skill-set, such as <a href="https://learnprompting.org/">this course for
                    learning prompting.</a> For this application, prompt engineering means we
                    send the context needed to answer the question (the journal notes), along
                    with the question itself.
                </p>
                <p>
                    This introduces another problem, there is a limit to the size of a prompt,
                    so I can't simply send all the journal notes. I need a clever way to select
                    relevant notes to send as the context. This is another NLP task, document
                    search, and I can use OpenAI's Embeddings API to help.
                </p>
                <p>
                    My roadmap is therefore as follows, I'll convert the set of journal notes
                    into embeddings and store them ahead of time. When I ask a query, I'll
                    generate a query embedding and use it to rank the notes by similarity to
                    the query using simple cosine distance. I then select the most relevant
                    notes and use them to construct a prompt for the text completion model and
                    use that to generate an answer.
                </p>
                <div class="image-container">
                    <img width="100%" src="../images/projects/gptjournal/inference_roadmap.png"/>
                    <p><i>The flow for how we generate an answer.</i></p>
                </div>

                <h3>Preparing the Journal Notes</h3>
                <p>
                    I use <a href="https://evernote.com/">Evernote</a> as a journal, and I was
                    able to export all the notes in a <code>.enex</code> file, which is XML.
                    From there, I need to read them into the application and get them into a
                    format that was easier to work with. I discovered <a
                        href="https://gist.github.com/foxmask/7b29c43a161e001ff04afdb2f181e31c">this gist</a>
                    that does the trick, and used it to load the notes into a list of
                    dictionaries.
                </p>
                <p>
                    The format I wanted was a list of strings, where each string was a journal
                    entry. This was a trivial case of processing each note (represented as a
                    dictionary) to generate a suitable text representation of the note.
                </p>
                <p>
                    The important steps in this process were to remove unusual characters
                    generated by the Evernote formatting. I also wanted to embed the date into
                    the text which was captured by the title of the note. In order to help the
                    language model understand when different events occured, I convert the
                    short form date into a sentence of the form <i>"the date is now
                    December 29 2022"</i> and prepend it to the start of the notes content.
                </p>
                <div class="image-container">
                    <img width="80%" src="../images/projects/gptjournal/preprocess_note.png"/>
                    <p><i>A function that takes in a note in dictionary form and generates the
                        textual representation of that note suitable for a large language model.
                        . I switched the date format I used a few years ago so I need to
                        account for both styles.</i></p>
                </div>
                <h3>Generating the Embeddings</h3>
                <p>
                    In this step, we generate embeddings for every note and store them alongside
                    the text.
                </p>
                 <div class="image-container">
                    <img width="100%" src="../images/projects/gptjournal/processing_roadmap.png"/>
                    <p><i></i></p>
                </div>
                <p>
                    OpenAI recently released a <a
                        href="https://openai.com/blog/new-and-improved-embedding-model/">new
                    and improved embeddings model</a>. This is convenient because previously we
                    had to use
                    two different models for both the query and the document embeddings, it was
                    also more expensive. With the notes in text form, generating embeddings is
                    trivial using the API.
                </p>

                <div class="image-container">
                    <img width="65%"
                         src="../images/projects/gptjournal/generating_embeddings.png"/>
                    <p><i></i></p>
                </div>
                <h3>Inference</h3>
                <p>
                    The steps to generate an answer to a query are simply those described in
                    the Roadmap section above. However, I sometimes find it useful to see the
                    code for clarifying details, so I copy in the relevant function below.
                </p>
                <p>
                    It's worth pointing out are that I use the latest
                    <code>text-davinci-003</code> model. It's the most capable model that
                    OpenAI have (as of December 2022), but it's also the most expensive. I also
                    select only the top three most relevant notes to use for the context.
                </p>
                <div class="image-container">
                    <img width="100%"
                         src="../images/projects/gptjournal/query_journal.png"/>
                    <p><i></i></p>
                </div>

                <h3>Results</h3>
                <p>
                    First I investigated how well it could answer questions about me and things
                    I've written about.
                </p>
                <p>
                    <code>query_journal('What is my job at Rovco?')</code>
                </p>
                <p>
                    <code><i>
                        'Your job at Rovco is likely related to data engineering and machine learning. You may also be involved in developing a data strategy, translating business ambitions to a technical roadmap, developing relationships with Rovco, creating a coherent and shared view of the way forward, and guiding tech teams.'
                    </i></code>
                </p>
                <p>
                    That's pretty accurate, I can't recall what I've written about my job, but
                    I don't believe I've ever simply described it. It seems to be picking this up
                    from activities I've written about related to the role.
                </p>
                <p>
                    <code>query_journal('What is my opinion on Les Mis?')</code>
                </p>
                <p>
                    <code><i>"I'm not a fan of musicals generally but Arnaud loved it."</i></code>
                </p>
                <p>
                    This is partly true, I don't like musicals, but I did like Les Mis. So did
                    Arnaud.
                </p>
                <p>
                    <code>query_journal('What was my experience of buying a house?')</code>
                </p>
                <p>
                    <code><i>"My experience of buying a house was positive overall. We found a
                        house that was very cheap, but it was in an area that wasn't ideal. We decided not to compromise on the area and kept looking for a nicer place. We eventually found a cottage that was still on the market and may make an offer on it if there's nothing wrong with it. We ended up completing the purchase and moving in, and the house is more than amazing. We are very happy with it and are still getting used to living together."</i></code>
                </p>
                <p>
                    This is bang on.
                </p>
                <p>
                    Next, I tried asking it to summarise what happened during particular days
                    or months. I started with an easy one.
                </p>
                <p>
                    <code>query_journal('What happened in March 2020?')</code>
                </p>
                <p>
                    <code><i>'In March 2020, the Coronavirus pandemic was becoming a massive deal, with the economy taking a plunge and the elderly being told to go into isolation. There was a lot of talk about the virus, and I spent time browsing the news and learning more about it. I was reassured by the fact that out of 1000 deaths in Italy, none were under 40, but I was reminded that the elderly were at risk. I also promised myself to do a postcard thing with the neighbours, letting them know my phone number in case they needed food picked up for them.'</i></code>
                </p>
                <p>
                    This is likely a blend of knowledge the model already has about the
                    pandemic, and the context that I provided to it. I would expect the model
                    to draw on both sources and blend them into a coherent answer.
                </p>
                <p>
                    <code>query_journal('What happened to me in February 2021?')</code>
                </p>
                <p>
                    <code><i>'In February 2021, I achieved a lot, finished and submitted an article on YOLO v2 and v3, read some articles, submitted coursework, did house searching with Susie, cooked dinner, paid in a check, had a call with Pete about TM, sorted out a mortgage agreement in principle with NatWest, started Good to Great, did some Dual N Back, and ate healthy.'</i></code>
                </p>
                <p>
                    This seems right, although it reads a bit like a shopping list of everything I
                    mentioned within the journal entries for that month. I want to point out two
                    things here. First, there is no way I can send all the journal entries for
                    that month, it would be too long for the prompt. I use three notes, so GPT
                    can only base its answer on three days worth of context. It looks like the
                    system is picking up on the journal notes which provide the most accurate
                    picture of what I was doing around that time.
                </p>
                <p>
                    Secondly, consider that the embeddings are successfully recalling the correct
                    journal notes for the requested date. I checked, and this is indeed what I
                    was doing around that date. Next I tried being more specific in my request.
                </p>
                <p>
                    <code>query_journal('Summarise what I did on February 25 2022?')</code>
                </p>
                <p>
                    <code>'On February 25 2022, I wrote code to compute the gradient of a convolution, which was a difficult task. I also went to Tortworth Court with Susie to look at the proposed wedding venue and met Dave the Toastmaster.'</code>
                </p>
                <p>
                    That's also correct. I suspect it's able to answer these kinds of questions
                    well because I embedded the date into the notes.
                </p>
                <p>
                    Finally, I generated some new ideas.
                </p>
                <p>
                    <code>query_journal("Based on places I've been, suggest new travel destinations and explain why it's suitable for me.")</code>
                </p>
                <p>
                    <code><i>'Based on my past travels, I would suggest exploring the Mediterranean region. Corfu, where I am planning to go, is a great destination for an "action" holiday, with lots of activities to keep me busy. I would also suggest exploring the Greek islands, as they offer a variety of activities and stunning scenery. Additionally, I would suggest exploring the Italian coast, as it offers a unique cultural experience and a variety of activities. Finally, I would suggest exploring the French Riviera, as it offers a luxurious and relaxing atmosphere. All of these destinations offer something unique and would be suitable for me based on my past travels.'</i></code>
                </p>
                <p>
                    I had to tweak this one until it worked, it kept trying to tell me places I
                    had already been. Also, I have already been to Corfu.
                </p>
                <h3>Discussion</h3>
                <p>
                    I was impressed, it was able to accurately answer questions about things
                    I'd done, and could summarise things that happened on certain dates. It was
                    okay at posing new ideas.
                </p>
                <p>
                    The biggest challenge was providing enough context to the model for it to
                    figure out the answer. This wasn't a problem with simple queries, but when
                    I ask the model to generate me ideas for things to try, it needs to know both
                    things I like doing and also what things are possible. I am only passing in
                    the context for things I like doing, so I'm relying on the model's knowledge
                    to suggest activities. If it doesn't have that knowledge then it's not
                    going to generate a good answer.
                </p>
                <p>
                    There is a rumour that the next generation of GPT will be able to search
                    the internet. This will solve this problem because the system will be able
                    to fetch the knowledge it needs.
                </p>
                <p>
                    Another problem I encountered was getting the system to understand
                    the temporal aspect of the notes. For example, consider the following.
                </p>
                <p>
                    <code>query_journal("What is Thea?")</code>
                </p>
                <p>
                    <code><i>'Thea is a web app that is being developed by Arnaud and the narrator. It is intended to be a VC-backed startup, but the narrator is uncertain about committing to it full-time.'</i></code>
                </p>
                <p>
                    That's correct, but I stopped working on Thea years ago. This isn't a
                    problem with the model, it's that the context I provide to it is written in
                    the present tense. I tried encoding the current date into the question, but
                    it still gets slightly confused.
                </p>
                <h3>Conclusion</h3>
                <p>
                    This was a fun project. I wanted to see how
                    easy it was to integrate natural language processing capabilities into my
                    projects, and it turns out it's surprisingly easy to do.
                </p>
                <p>
                    Language modelling is going to evolve over the next year. GPT4 is due to be
                    released soon. This means that applications like the one discussed in this
                    post will only become more effective and useful. I look forward to seeing
                    what the community can do with this new tech.
                </p>

                <br />
                <div id="disqus_thread"></div>
                <script>
                    var disqus_config = function () {
                    this.page.url = "https://www.harrysprojects.com/projects/gptjournal.html";
                    this.page.identifier = "gptjournal";
                    };

                    (function() { // DON'T EDIT BELOW THIS LINE
                    var d = document, s = d.createElement('script');
                    s.src = 'https://harrysprojects-com.disqus.com/embed.js';
                    s.setAttribute('data-timestamp', +new Date());
                    (d.head || d.body).appendChild(s);
                    })();
                </script>
                <noscript>Please enable JavaScript to view the <a target="_blank" href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

                <br />
                <br />
            </div>

        </div>
    </body>
    <footer>
    </footer>
</html>